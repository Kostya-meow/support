# Презентация: AI Support Desk — ИИ техподдержка для IT-предприятия

Ниже — текстовая версия слайдов презентации для хакатона. Используйте как план для слайдов: проблема, решение, архитектура, демо, фичи, метрики и вывод для жюри.

---

## Слайд 1 — Заголовок

AI Support Desk — интеллектуальная техподдержка для IT-предприятия

- Команда: [Ваши имена]
- Тема: автоматизация первых линий поддержки, ускорение ответа и масштабирование операционной команды с помощью RAG и мультиканальной интеграции

---

## Слайд 2 — Проблематика

- Человеческий фактор: ограниченное число операторов не справляется с ростом обращений
- Длительное время первого ответа — пользователи недовольны, теряются SLA
- Повторяющиеся вопросы и незнание базы знаний приводят к неэффективной работе
- Необходимость контролировать токсичность, спам и нецелевые обращения

Почему это важно для экспертов:
- Время реакции напрямую влияет на бизнес-показатели (удержание, продуктивность команд)
- Автоматизация рутинных задач высвобождает инженеров для важных инцидентов

---

## Слайд 3 — Цель проекта

Создать надёжную, контролируемую и объяснимую систему ИИ-техподдержки, которая:

- Отвечает на частые запросы автоматически (до 3 уровней автоматизации)
- Направляет сложные/чувствительные кейсы к операторам
- Поддерживает Telegram и VK, веб-дашборд и API для интеграций
- Фильтрует спам, нецелевые обращения и применяет цензуру

---

## Слайд 4 — Высокоуровневая архитектура (пайплайн)

1) Входящие сообщения (Telegram, VK, Web/API, тестовый симулятор)
2) Предобработка: очистка, проверка на спам/токсичность, маршрутизация
3) Retrieval (RAG): поиск релевантных записей в базе знаний (Knowledge Base)
4) Классификация и уровни автоматизации:
   - Уровень 1 — быстрый автоматический ответ (шаблон/FAQ)
   - Уровень 2 — составление ответа с использованием контекста из KB + LLM
   - Уровень 3 — генерация сложного ответа с обоснованием (RAG + цитаты из KB)
5) Валидация и модерация: антиспам, фильтры, цензура
6) Логирование, метрики, обновление популярности вопросов

---

## Слайд 5 — Технологии и стек

- Backend: FastAPI (ASGI), asyncio
- БД: SQLAlchemy + PostgreSQL (асинхронные сессии)
- Модуль поиска/embeddings: sentence-transformers или облачные векторные сервисы
- RAG: комбинированный pipeline — эмбеддинги + LLM (любой совместимый)
- Боты: aiogram для Telegram, кастомная интеграция для VK
- Web UI: Jinja2 шаблоны + WebSocket realtime (дашьборд операторов)
- Тестирование/симулятор: встроенный симулятор диалогов для нагрузочного и функционального теста
- Дополнительно: ngrok/локальный запуск для демо, dotenv для конфигов

Примечание: ниже — точный стек, извлечённый из кода (фактически используемые библиотеки и инфраструктура).

---

## Фактический стек (по коду)

- Python 3.x
- FastAPI — веб-приложение и REST/WS API
- aiogram — Telegram bot integration (dispatcher, handlers, inline-кнопки)
- vk_api — VK бот (VkLongPoll / VkBotLongPoll) с fallback-логикой и поддержкой клавиатур/фолбэков
- SQLAlchemy (async) + aiosqlite — используются SQLite базы: `db/tickets.db` и `db/knowledge.db` (конфиг в `app/database.py`)
- sentence-transformers — эмбеддинги (настройка через configs/rag_config.yaml)
- faiss (faiss-cpu) — векторный индекс для поиска по базе знаний
- rank-bm25 — (импортируется в коде для альтернативного ранжирования)
- openai (официальный клиент OpenAI) — клиент LLM через универсальный обёртчик (используется в RAG)
- transformers (BERT) — модель для классификации токсичности (опционально, если задан путь модели)
- SpeechRecognition + imageio[ffmpeg] (ffmpeg) — для распознавания голосовых сообщений и конвертации аудио в WAV
- pydub, python-multipart, jinja2, numpy, pandas и пр. — утилитарные библиотеки
- pyngrok — для демонстрации/локального туннелирования (в проекте есть скрипты)

Инфраструктурные детали:

- БД — SQLite (локальные файлы `db/tickets.db`, `db/knowledge.db`) через драйвер `sqlite+aiosqlite` (не PostgreSQL)
- Асинхронные сессии организованы через `async_sessionmaker` в `app/database.py`
- Конфигурация загружается из `configs/` директории (RAG настройки, настройки приложения, симулятор)

---

## Слайд 6 — Компоненты сервиса (фичи)

---

## Слайд 6 — Компоненты сервиса (фичи)

- Сервис / API
  - REST/WS эндпоинты для создания заявок, отправки/получения сообщений, получения статистики
- Симулятор
  - Генерация реальных сценарием запросов для тестирования автоматически
  - Позволяет моделировать нагрузку и поведение пользователей
- Дашборд
  - Реальное время: входящие заявки, чаты, очередь, метрики SLA
  - Инструменты оператора: ответ, эскалация, пометка прочитано/непрочитано
- Заявки (tickets)
  - Хранение переписки, статусы, приоритеты, история действий
- Telegram и VK боты
  - Мультиканальная интеграция с корректной маршрутизацией и контекстом
- Автоматический FAQ (3 уровня)
  - Уровень 1: быстрые ответы по шаблону
  - Уровень 2: ответы на основе топ-K релевантных записей из KB
  - Уровень 3: генерация с указанием источников (RAG) + confidence score
- Фильтры: нецелевое, цензура, антиспам
  - Сегментация и блокировка нежелательного контента

Дополнительные реализованные фичи (обнаружено в коде):

- Поддержка голосовых сообщений от пользователя: аудио конвертируется в WAV (через ffmpeg), затем распознаётся библиотекой SpeechRecognition (используется Google API через recognizer.recognize_google как fallback). Это есть в `RAGService.SpeechToTextService`.
- Inline-кнопки и callback-обработка в Telegram (aiogram): запрос оператора, подтверждение эскалации и кнопки «углубиться в вопрос/подробнее» — `bot.py` содержит клавиатуры и callback_map.
- VK: клавиатурный fallback — если VK-клиент не поддерживает inline-кнопки, отправляется нумерованный текст с опциями и модуль `pending_options` хранит соответствие номеров → текст опции.
- Симулятор диалогов: `SimulatorService` генерирует вопросы, оценивает ответы через LLM, хранит сессии, даёт подсказки и оценивает баллы (код в `app/simulator_service.py`).
- RAG-пайплайн с конкретной реализацией: хранение embedding как бинарных данных в БД, FAISS-индекс, и API поиска/перестроения KB (`app/retrieval.py`, `app/rag_service.py`, `app/retrieval.py` реализует KnowledgeBase).
- Генерация summary тикета: при создании тикета бот вызывает `rag_service.generate_ticket_summary(...)` и summary сохраняется в базе (см. `bot.py` / `vk_bot.py`).
- История чата включается при создании тикета — бот пытается подтянуть последние сообщения и добавить их в тикет (см. логику в `create_ticket_and_add_message`), это помогает в контекстировании RAG.
- Подсчёт unread_count и логика пометки сообщений прочитанными при активных соединениях в дэшборде (websocket) — в `main.py` и `bot.py`.
- Фоновая задача обновления популярности вопросов (score popularity) — `update_popularity_scores` в `main.py` (пересчитывает популярность записей KB на основе похожести запросов за 24 часа).
- Токсичность/фильтры: есть опциональный классификатор на BERT (в `rag_service.py`) для оценки токсичности и пороговой фильтрации сообщений.
- Метрики и аналитика: есть функции расчёта среднего времени ответа, счётчики, скрипты и методы для выгрузки статистики, которые используются в дашборде/боте.
- WebSocket realtime менеджер (`app/realtime.py`) для передачи live-обновлений на дашборд.
- Поддержка NGROK/локального туннеля (скрипты и утилиты присутствуют) для демонстрации извне.

Возможные упущенные/малозаметные реализации (рекомендации проверить):

- Наличие готовых миграций и backup-файлов (в репозитории есть `migrate_*.py`, проверить выполнения миграций для прод-сценариев).
- Проверить, подключён ли путь к модели токсичности в `configs/rag_config.yaml` — если не задан, классификатор выключен.

---

## Уточнения — моменты, где я ошибся ранее

- Я предполагал PostgreSQL — фактически в коде использованы локальные SQLite базы через `sqlite+aiosqlite`.
- Я говорил про «облачные векторные сервисы» как опцию — в текущем коде используется локальный `sentence-transformers` + FAISS. Конфиг позволяет сменить модель, но хранилище и индекс локальные.

---

## Что можно добавить в презентацию (коротко)

- Отдельный слайд «Фактический стек (по коду)» с перечислением библиотек и примечанием про SQLite vs прод БД
- Слайд «Реализованные фичи — детали» с перечислением голосовых сообщений, клавиатур и fallback-логики для VK, генерации summary, симулятора, популярности вопросов и токсичности
- В демо отдельно показать: голосовое сообщение → транскрипция → ответ; VK-клавиатура → fallback; симулятор прогон нескольких сессий


---

## Слайд 7 — Как это работает в диалоге (пример)

Пример пользовательского запроса: «Не могу подключиться к VPN. Ошибка 800»

1) Сервис получает сообщение из Telegram
2) Фильтр проверяет, что это не спам и не токсичное сообщение
3) Retrieval ищет релевантные KB-записи: найдены инструкции по ошибке 800
4) Уровень 2 формирует ответ: краткое решение + ссылка на детальную инструкцию
5) Если уверенность низкая — пометка и эскалация к оператору с контекстом и найденными источниками

---

## Слайд 8 — Метрики и ожидаемые результаты (предложение)

Доработанные метрики и план тестирования (PILOT / HACKATHON)

Ключевые KPI (определения и целевые значения для презентации):

- Median First Response Time (FR) — медиана времени до первого ответа (бот или оператор). Цель хакатона: снизить с baseline (примерно 45 мин) до 10–15 мин в пилоте.
- Auto-resolved Rate — доля обращений, полностью решённых без вмешательства оператора (закрыты автоматически). Цель: 30–50% в целевом сценарии для частых FAQ.
- Escalation Rate — доля обращений, требующих передачи оператору. Цель: снижение на 40–70% относительно baseline.
- Correctness (human-reviewed) — доля автоматически закрытых ответов, признанных корректными ревьюером. Цель: >= 85% для уровней 1–2.
- Filter False Positive Rate — доля корректных сообщений, ошибочно отфильтрованных как спам/токсичные. Цель: <1.5% (чем ниже, тем лучше).
- CSAT delta — изменение пользовательской удовлетворённости (опрос после обращения). Цель: +8–15% в пилоте.
- RAG latency — 95-й перцентиль времени генерации ответа (включая поиск по FAISS и вызов LLM). Цель: P95 &lt; 6s (P50 &lt; 2s при кэше).

План тестирования и валидации (как мы измеряем):

1) Нагрузочный симулятор
   - Использовать `SimulatorService` для генерации 1k–10k обращений в регулируемых сценариях (easy/medium/hard).
   - Измерять throughput (messages/sec), время RAG (P50/P95), и долю автозакрытий.
2) Качество ответов (human-in-the-loop)
   - Случайная выборка 500 автоматических ответов для ручной разметки (две ревьюера, разрешение конфликтов третий).
   - Рассчитать accuracy, precision/recall для auto-resolve, и false-positive фильтров.
3) A/B тестирование (пилотное развертывание)
   - Канал A: существующие операторы (baseline)
   - Канал B: AI Support Desk (с автоматикой и эскалацией)
   - Сравнить FR, CSAT, нагрузку на операторов через 2–4 недели и применить t-test / bootstrap для статистики.
4) SLA и бизнес-метрики
   - Измерять влияние на ключевые SLA (median FR, time-to-resolution), а также на операционные метрики (количество операций в час на оператора).

Примеры реалистичных результатов (для слайдов — гипотетические, но правдоподобные):

- Baseline (до внедрения): median FR = 45 мин, auto-resolved = 5%, escalation = 95%, CSAT = 72%
- После 4 недель пилота: median FR = 12 мин, auto-resolved = 38%, escalation = 57% (−40%), CSAT = 82% (+10%)
- После оптимизаций (2–3 месяца): median FR = 8 мин, auto-resolved = 45–50%, escalation = 50% (−47%), CSAT = 85% (+13%)

Метрики качества модели и пороги принятия решений:

- Confidence score &gt; 0.6 → автоматический ответ с предложением углубиться (кнопка)
- Confidence score между 0.4–0.6 → автоматический черновик/варианты, требующие подтверждения оператора
- Confidence score &lt; 0.4 → немедленная эскалация к оператору

Как мы считаем auto-resolved: тикет считается автоматически решённым, если после автоматического ответа в течение N часов (например, 24 ч) пользователь не отправил уточняющий запрос и тикет закрыт автоматически/система пометила задачу решённой.

---

## Краткие тексты для слайдов (PPTX-ready)

Ниже — короткие, готовые к переносу на слайды заголовки и bullets (каждый слайд — 3–5 пунктов).

- Слайд 1: Заголовок
  - AI Support Desk — ИИ-техподдержка для IT
  - RAG + KB + мультиканалы (TG, VK, Web)

- Слайд 2: Проблема
  - Рост обращений при фиксированном штате операторов
  - Долгое время ответа и потеря SLA
  - Повторяющиеся вопросы и ручная маршрутизация

- Слайд 3: Решение (коротко)
  - Мультиканальная автоматизация (3 уровня)
  - RAG с объяснениями и источниками
  - Фильтры: антиспам, цензура, токсичность

- Слайд 4: Архитектура
  - Входы: TG, VK, Web, симулятор
  - Preprocess → Retrieval (FAISS+SBERT) → LLM → Moderation
  - WebSocket дашборд для операторов

- Слайд 5: Фичи (коротко)
  - Автоматические ответы на 3 уровнях
  - Голосовые сообщения → транскрипция
  - Симулятор и генерация summary тикета

- Слайд 6: Метрики (ключевые)
  - Median FR, Auto-resolve %, Escalation %, Correctness, CSAT
  - P95 RAG latency & throughput

- Слайд 7: Демо (порядок)
  - 1) TG: голос → транскрипция → ответ
  - 2) TG/VK: FAQ → автоответ → кнопка «углубиться» → эскалация
  - 3) Дашборд: live queue, SLA, summary

- Слайд 8: Риски и mitigation
  - Неверные ответы → confidence + RAG + ревью
  - Конфиденциальность → фильтры и политика хранения

- Слайд 9: Roadmap
  - Апгрейд KB, A/B, безопасность, прод-интеграция

---

## Демо-скрипты (чек-лист и ожидаемые результаты)

Сценарий A — Быстрый FAQ (идеальный кейс)

1) Оператор/демонстратор: отправляет в Telegram текстовый вопрос из списка FAQ (например, "Как подключиться к VPN — ошибка 800").
2) Система: мгновенно ищет релевантную запись в KB и отвечает шаблоном + ссылкой на инструкцию.
3) Ожидаемый результат: ответ отправлен < 5–15 с, тикет закрыт автоматически (auto-resolved) через 24 ч при отсутствии уточнений, показан источник/цитата.

Сценарий B — Низкая уверенность и эскалация

1) Отправляем сложный/неоднозначный вопрос.
2) Система генерирует ответ с низкой confidence (0.3–0.5) и предлагает варианты/черновик или кнопку "Попросить оператора".
3) Демонстрируем на дашборде: оператор получает контекст, найденные KB-источники и кнопку "подтвердить и отправить".
4) Ожидаемый результат: эскалация видна, оператор берет кейс с контекстом, время подготовки ответа сокращено.

Сценарий C — Голосовое сообщение пользователя

1) Пользователь присылает голосовое сообщение в Telegram.
2) Система: сохраняет голос, при необходимости конвертирует в wav, запускает STT, получает текст и прогоняет RAG.
3) Ожидаемый результат: транскрипт виден в тикете, система предлагает ответ; при высокой уверенности ответ отправляется автоматически.

Сценарий D — VK-клавиатура и fallback

1) Отправляем пользователю VK сообщение с клавиатурой (или с вариантами). Если клиент не поддерживает inline, пользователь получает нумерованный список.
2) Ожидаемый результат: пользователь отвечает цифрой — backend сопоставляет через `pending_options` и выполняет действие; оператор/лог сервируется в дашборде.


---

## Слайд 9 — Демо (что показать)

1) Короткий сценарий: пользователь пишет в Telegram — система отвечает автоматически, тикет закрывается
2) Сценарий с низкой уверенностью: система показывает варианты ответов и эскалирует к оператору, оператор видит контекст и источники
3) Дашборд: показ очереди, SLA, live-messages
4) Симулятор: запуск нескольких сессий для демонстрации нагрузки и роста популярности вопросов

Совет: заранее подготовьте пару сценариев с хорошо предсказуемым результатом, чтобы жюри увидели полностью работающий цикл

---

## Слайд 10 — Риски и способы их снижения

- Неверные ответы от LLM — решение: confidence scores, RAG с явными ссылками на KB, деплой модерации
- Конфиденциальность данных — решение: фильтрация личных данных, политика хранения, возможность оффлайн-инференса
- Спам и злоупотребления — решение: автоматы фильтры и лимиты
- Интеграция в продакшен — решение: API-first дизайн и адаптеры для мессенджеров

---

## Слайд 11 — План работ / Roadmap

Короткий план развития после хакатона:

1) Тонкая настройка RAG и регулярный апдейт KB (ETL из тикетов)
2) Автоматическое обучение/пересборка эмбеддингов
3) Усовершенствование политики эскалации и routing-а
4) Метрики и A/B тестирование стратегий автоматизации
5) Безопасность, аудит и соответствие требованиям

---

## Слайд 12 — Заключение (аргументы для жюри)

- Решаем реальную операционную проблему: сокращаем время ответа и нагрузку на команду
- Подход RAG обеспечивает объяснимость и контроль — важно для enterprise
- Мультиканальная архитектура и симулятор дают быструю валидацию и масштабирование
- Проект готов к пилоту: есть дашборд, интеграции, симулятор и pipeline для обновления KB

---

## Приложение: подсказки для демонстрации и Q&A

- Будьте готовы ответить на вопросы про безопасность данных и SLA
- Подчеркните объяснимость ответов (откуда берутся данные для ответа)
- Опишите, как обновляется и валидируется KB
- Если спросят про стоимость — предложите гибридное использование локальных эмбеддеров и облачных LLM

---

Спасибо! Удачи на хакатоне — хотите, улучшим текст/переведём в слайды PowerPoint/Google Slides?
